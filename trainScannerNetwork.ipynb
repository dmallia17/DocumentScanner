{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainScannerNetwork.ipynb\n",
    "\n",
    "## Author: Daniel Mallia\n",
    "## Date Begun: 1/17/2020\n",
    "\n",
    "**This Jupyter Notebook contains the process for training a Keras network for Optical Character Recognition (OCR) for use with a document scanner app, on the Chars74K Dataset. See the following citation and link for the dataset:**\n",
    "\n",
    "T. E. de Campos, B. R. Babu and M. Varma. Character recognition in natural images. In Proceedings of the International Conference on Computer Vision Theory and Applications (VISAPP), Lisbon, Portugal, February 2009. \n",
    "\n",
    "\n",
    "http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, training will only be done on the \"Fnt\" folder, which contains computer font characters, of 4 different variations. This data comes as a single folder with a directory for each class - thus we must split into train/test file sets before using a validation split on the training data generator.\n",
    "\n",
    "Inspiration from how to handle this in part from here: \n",
    "https://stackoverflow.com/questions/46717742/split-data-directory-into-training-and-test-directory-with-sub-directory-structu\n",
    "\n",
    "and \n",
    "\n",
    "https://stackoverflow.com/questions/8505651/non-repetitive-random-number-in-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainDataLocation = '/Users/danielmallia/Documents/TTP/IndependentStudy/Capstone/Data/English/Fnt/'\n",
    "# testDataLocation = '/Users/danielmallia/Documents/TTP/IndependentStudy/Capstone/Data/English/FntTest/'\n",
    "\n",
    "# # For each sample folder\n",
    "# for folder in os.listdir(trainDataLocation):\n",
    "#     if(folder == '.DS_Store'): # Ignore .DS_Store files\n",
    "#         continue\n",
    "#     else: \n",
    "#         # Make a matching test folder\n",
    "#         testPath = testDataLocation + folder + '/'\n",
    "#         os.mkdir(testPath)\n",
    "        \n",
    "#         currentFolderPath = trainDataLocation + folder + '/'\n",
    "#         FILE_NAME_LIST = os.listdir(currentFolderPath)\n",
    "#         numberOfFiles = len(FILE_NAME_LIST)\n",
    "#         numRange = np.arange(0, numberOfFiles)\n",
    "#         numOfSelections = math.floor(numberOfFiles * .2)\n",
    "        \n",
    "#         # Randomly select indices for choosing approximately 20% of the samples\n",
    "#         randomNumGen = default_rng()\n",
    "#         testSelections = randomNumGen.choice(numRange, size=numOfSelections, replace=False)\n",
    "        \n",
    "#         # For each index selected\n",
    "#         for index in testSelections:\n",
    "#             filename = FILE_NAME_LIST[index]\n",
    "#             shutil.move(currentFolderPath + filename, testPath + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOT DOING DATA AUGMENTATION BECAUSE OTHERWISE THIS WILL ALSO BE APPLIED TO THE VALIDATION DATA.\n",
    "THIS IS A KNOWN ISSUE WITH KERAS, SEE:**\n",
    "\n",
    "https://stackoverflow.com/questions/53037510/can-flow-from-directory-get-train-and-validation-data-from-the-same-directory-in\n",
    "\n",
    "This is useful for understanding how to do the train/validation split: https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "\n",
    "Useful for understanding the matter of class labels with Keras: https://medium.com/difference-engine-ai/keras-a-thing-you-should-know-about-keras-if-you-plan-to-train-a-deep-learning-model-on-a-large-fdd63ce66bd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40362 images belonging to 62 classes.\n",
      "Found 10044 images belonging to 62 classes.\n",
      "Found 12586 images belonging to 62 classes.\n"
     ]
    }
   ],
   "source": [
    "trainDataLocation = '/Users/danielmallia/Documents/TTP/IndependentStudy/Capstone/Data/English/Fnt/'\n",
    "testDataLocation = '/Users/danielmallia/Documents/TTP/IndependentStudy/Capstone/Data/English/FntTest/'\n",
    "\n",
    "imageSize = (128, 128) # Chars 74k image size\n",
    "\n",
    "# Initialize generators - just appropriate scaling and validation split\n",
    "trainDataGen = ImageDataGenerator(rescale=1./255, validation_split=.2)\n",
    "testDataGen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow from directories\n",
    "\n",
    "trainGenerator = trainDataGen.flow_from_directory(trainDataLocation,\n",
    "                             target_size=imageSize,\n",
    "                             class_mode=\"categorical\",\n",
    "                             subset=\"training\")\n",
    "\n",
    "validationGenerator = trainDataGen.flow_from_directory(trainDataLocation,\n",
    "                                  target_size=imageSize,\n",
    "                                  class_mode=\"categorical\",\n",
    "                                  subset=\"validation\")\n",
    "\n",
    "testGenerator = testDataGen.flow_from_directory(testDataLocation,\n",
    "                           target_size=imageSize,\n",
    "                           class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "classLabels = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    classLabels.append(str(i))\n",
    "for i in range(ord('A'), ord('Z') + 1):\n",
    "    classLabels.append(chr(i))\n",
    "for i in range(ord('a'), ord('z') + 1):\n",
    "    classLabels.append(chr(i))\n",
    "    \n",
    "print(classLabels)\n",
    "print(len(classLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sample001': '0', 'Sample002': '1', 'Sample003': '2', 'Sample004': '3', 'Sample005': '4', 'Sample006': '5', 'Sample007': '6', 'Sample008': '7', 'Sample009': '8', 'Sample010': '9', 'Sample011': 'A', 'Sample012': 'B', 'Sample013': 'C', 'Sample014': 'D', 'Sample015': 'E', 'Sample016': 'F', 'Sample017': 'G', 'Sample018': 'H', 'Sample019': 'I', 'Sample020': 'J', 'Sample021': 'K', 'Sample022': 'L', 'Sample023': 'M', 'Sample024': 'N', 'Sample025': 'O', 'Sample026': 'P', 'Sample027': 'Q', 'Sample028': 'R', 'Sample029': 'S', 'Sample030': 'T', 'Sample031': 'U', 'Sample032': 'V', 'Sample033': 'W', 'Sample034': 'X', 'Sample035': 'Y', 'Sample036': 'Z', 'Sample037': 'a', 'Sample038': 'b', 'Sample039': 'c', 'Sample040': 'd', 'Sample041': 'e', 'Sample042': 'f', 'Sample043': 'g', 'Sample044': 'h', 'Sample045': 'i', 'Sample046': 'j', 'Sample047': 'k', 'Sample048': 'l', 'Sample049': 'm', 'Sample050': 'n', 'Sample051': 'o', 'Sample052': 'p', 'Sample053': 'q', 'Sample054': 'r', 'Sample055': 's', 'Sample056': 't', 'Sample057': 'u', 'Sample058': 'v', 'Sample059': 'w', 'Sample060': 'x', 'Sample061': 'y', 'Sample062': 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Generate mapping dictionary\n",
    "#print(trainGenerator.class_indices)\n",
    "\n",
    "i = 0\n",
    "mapping = {}\n",
    "for key in trainGenerator.class_indices:\n",
    "    #print(trainGenerator.class_indices[key])\n",
    "    mapping[key] = classLabels[i]\n",
    "    i+=1\n",
    "    \n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3))) # height, width, channels\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 368,606\n",
      "Trainable params: 368,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "631/631 [==============================] - 105s 166ms/step - loss: 1.1180 - accuracy: 0.7049 - val_loss: 0.6150 - val_accuracy: 0.8324\n",
      "Epoch 2/2\n",
      "631/631 [==============================] - 103s 163ms/step - loss: 0.5269 - accuracy: 0.8310 - val_loss: 0.4674 - val_accuracy: 0.8365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x637dbf850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfTrainingFiles = len(trainGenerator.filepaths)\n",
    "numOfValidationFiles = len(validationGenerator.filepaths)\n",
    "batchSize = 64\n",
    "\n",
    "trainSteps = math.ceil(numOfTrainingFiles / batchSize)\n",
    "validationSteps = math.ceil(numOfValidationFiles / batchSize)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "trainAndValidationHistory = model.fit_generator(\n",
    "        trainGenerator,\n",
    "        steps_per_epoch=trainSteps,\n",
    "        epochs=5,\n",
    "        validation_data=validationGenerator,\n",
    "        validation_steps=validationSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training and Validation Performance:\n",
    "Uses the same plotting method demonstrated in Deep Learning with Python by Francois Chollet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDictionary = trainAndValidationHistory.history\n",
    "lossValues = historyDictionary['loss'] # Extract loss values\n",
    "validationLossValues = historyDictionary['val_loss'] # Extract validation loss values\n",
    "\n",
    "epochs = range(1, len(lossValues) + 1)  # Number of epochs\n",
    "\n",
    "plt.plot(epochs, lossValues, 'ro', label='Training loss') # ro = red circle\n",
    "plt.plot(epochs, validationLossValues, '-r', label='Validation loss') # -r = red line\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf() # Clears figure\n",
    "accuracy = historyDictionary['acc']\n",
    "validationAccuracy = historyDictionary['val_acc']\n",
    "\n",
    "plt.plot(epochs, accuracy, 'go', label='Training acc') # go = green circle\n",
    "plt.plot(epochs, validationAccuracy, '-g', label='Validation acc') # -g = green line\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfTestFiles = len(testGenerator.filepaths)\n",
    "batchSize = 64\n",
    "\n",
    "model.evaluate_generator(testGenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('OCRNetwork.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning] *",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
